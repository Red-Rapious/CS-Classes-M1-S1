\section{Camera Calibration}
\emph{Camera calibration} is the process of estimating the parameters of a camera model that relate the 3D world coordinates of a point to its 2D image coordinates. The camera parameters are represented in a \emph{camera matrix} of shape $3\times4$, which essentially projects a 3D point (in homogeneous coordinates) to a 2D point. 

The camera matrix is composed of two matrices: the \emph{intrinsic matrix} and the \emph{extrinsic matrix}. The intrinsic matrix contains the parameters that are specific to the camera, such as the focal length, the principal point, and the skew coefficient. The extrinsic matrix contains the parameters that describe the position and orientation of the camera in the world coordinate system.

\subsection{Least squares calibration}
\label{subsec:least-squares-calibration}
Consider a set of $n$ points $p_i\in\R^3$ and $P_i\in\R^4$, respectively the homogeneous coordinates of the 2D and 3D points that we will use for calibration:
\begin{equation*}
    p_i = \begin{bmatrix} u_i \\ v_i \\ 1 \end{bmatrix} \quad\text{and}\quad P_i = \begin{bmatrix} x_i \\ y_i \\ z_i \\ 1 \end{bmatrix}
\end{equation*}
Each point $p_i$ corresponds to the 2D projection of the 3D point $P_i$ in the camera frame. We want to estimate the camera matrix $M\in\mathscr{M}_{3,4}(\R)$, such that:
\begin{equation}
    \label{eq:projection}
    \forall i\in\iset{1}{n}, \quad p_i = \frac{1}{z_i}MP_i
\end{equation}
Let's denote $m_1$, $m_2$, and $m_3$ the rows of $M$, such that:
\begin{equation*}
    M = \begin{bmatrix} m_1 \\ m_2 \\ m_3 \end{bmatrix}
\end{equation*}
We can rewrite \eqref{eq:projection} as:
\begin{equation}
    \label{eq:projection2}
    \forall i\in\iset{1}{n}, \quad u_i = \frac{\frac{1}{z_i}m_1P_i}{\frac{1}{z_i}m_3P_i} \quad\text{and}\quad v_i = \frac{\frac{1}{z_i}m_2P_i}{\frac{1}{z_i}m_3P_i}
\end{equation}
By clearing the denominators, we see that \eqref{eq:projection2} is equivalent to:
\begin{equation}
    \label{eq:projection3}
    \forall i\in\iset{1}{n}, \quad A_iX = 0_2
\end{equation}
where
\begin{equation*}
    A := \begin{bmatrix}
        P_i^\tp & O_4^\tp & -u_iP_i^\tp \\
        O_4^\tp & P_i^\tp & -v_iP_i^\tp
    \end{bmatrix}\in\mathscr{M}_{2,12}(\R)
    \quad\text{and}\quad
    X := \begin{bmatrix} m_1^\tp \\ m_2^\tp \\ m_3^\tp \end{bmatrix}\in\R^{12}
\end{equation*}

In practice, it is likely that \eqref{eq:projection3} will not be exactly satisfied for all $i\in\iset{1}{n}$, due to noise in the measurements. Therefore, we will not solve this exact problem, but instead solve the following minimisation problem:
\begin{equation}
    \hat{X} = \argmin_{\norm{X}^2=1} \norm{\sum_iA_iX}_2^2 = \argmin_{\norm{X}^2=1} \norm{AX}_2^2
\end{equation}
where:
\begin{equation*}
    A := \begin{bmatrix}
        A_1 \\ A_2 \\ \vdots \\ A_n
    \end{bmatrix}
    = \begin{bmatrix}
        P_1^\tp & O_4^\tp & -u_1P_1^\tp \\
        O_4^\tp & P_1^\tp & -v_1P_1^\tp \\
        \vdots & \vdots & \vdots \\
        P_n^\tp & O_4^\tp & -u_nP_n^\tp \\
        O_4^\tp & P_n^\tp & -v_nP_n^\tp
    \end{bmatrix} \in\mathscr{M}_{2n,12}(\R)
\end{equation*}

This can be solved using the \emph{Singular Value Decomposition} (SVD) of $A$. If $A = U\Sigma V^\tp$ is the SVD of $A$, then the solution $\hat{X}$ is given by the last column of $V$. Given $\hat{X}$, we can then extract the estimation of the camera matrix $\hat{M}$, by reshaping $\hat{X}\in\R^{12}$ into a $3\times4$ matrix.

\begin{remark}
    Estimating $M$ does not give any explicit information on $z_i$; when projecting into the 2D plane, the $u$ and $v$ coordinates can be recovered by normalizing the projection by the third estimated value, which rescales by ensuring that the third coordinate is equal to 1.
\end{remark}

\subsection{Parameter decomposition}
Once the camera matrix $M$ has been estimated, we can decompose it into its intrinsic and extrinsic parameters. One can show that any projection matrix $M$ can be decomposed into the following form:
\begin{equation*}
    M=\mathcal{K} [R | t]
\end{equation*}
where:
\begin{equation*}
    \mathcal{K} = \begin{bmatrix}
        \alpha&-\alpha\cot\theta&u_0\\
        0 & \beta/\sin\theta & v_0\\
        0 & 0 & 1
    \end{bmatrix}
    \quad\quad\text{and}\quad\quad
    R = \begin{bmatrix} r_1^T \\ r_2^T \\ r_3^T \end{bmatrix}
\end{equation*}
Here, we denote by $r_1, r_2, r_2\in\R^3$ the rows of the rotation matrix, and $\theta$ the skew rotation angle.

For a certain scale factor $\rho\in\R$, it is shown that:
\begin{equation*}
    \rho M = \begin{bmatrix}
        \alpha r_1 - \alpha\cot\theta r_2 & \alpha t_x-\alpha\cot\theta t_y+u_0 t_z\\
        \frac{\beta}{\sin\theta}r_2 + v_0 r_3 & \frac{\beta}{\sin\theta}t_y+v_0 t_z\\
        r_3 & t_z
    \end{bmatrix}
\end{equation*}
The normalisation by $\rho$ comes from the fact that the Frobenius norm of the rotation matrix is equal to 1. Furthermore, we know from the rotation matrices properties that they are orthogonal ($R^\tp R=I_3$), and that the determinant of a rotation matrix is equal to 1. Hence, we have:
\begin{equation*}
    \forall i\in\iset{1}{3}, \quad \norm{r_i}^2 = 1
\end{equation*}

If we write $M=[\A b]$ with $b\in\R^3$ the last column of $M$, and $a_1, a_2, a_3\in\R^3$ the columns of $\A$, we have by identification that:
\begin{equation*}
    \rho a_3 = r_3
\end{equation*}
Hence, we can deduce the scale factor $\rho$:
\begin{equation*}
    \rho = \frac{\epsilon}{\norm{a_3}}
\end{equation*}
where $\epsilon=\pm 1$. The choice of $\epsilon$ determines the orientation of the camera. In practical situations, the sign of $t_z$ is often known, since it corresponds to knowing whether the origin of the world coordinate system is in front of or behind the camera.

Using the orthogonality of the rotation matrix, we have that:
\begin{equation*}
    r_i^\tp\cdot r_j = \begin{cases}
        1 & \text{if } i=j\\
        0 & \text{otherwise}
    \end{cases}
\end{equation*}
Hence:
\begin{equation*}
    r_3^\tp(\alpha r_1-\alpha\cot\theta r_2 + u_0r_3) = (\rho a_3)\cdot(\rho a_1)
\end{equation*}
Which gives us:
\begin{equation*}
    u_0 = \rho^2a_3\cdot a_1
\end{equation*}
Similarly, we can find that:
\begin{equation*}
    v_0 = \rho^2a_3\cdot a_2
\end{equation*}

It can also be shown that we can recover the skew rotation angle $\theta$ by computing:
\begin{equation*}
    \cos\theta = \frac{(a_1\times a_3)\cdot(a_2\times a_3)}{||a_1\times a_3||||a_2\times a_3||}
\end{equation*}
The skew rotation angle can later be used to retrieve the values of $\alpha$ and $\beta$:
\begin{equation*}
\alpha = \rho^2||a_1\times a_3||\sin\theta
\end{equation*}
\begin{equation*}
\beta = \rho^2||a_2\times a_3||\sin\theta
\end{equation*}

We then have all the elements to compute the lines of $R$:
\begin{equation*}
\begin{cases}r_1 = \frac{a_2\times a_3}{||a_2\times a_3||}\\
r_3 = \rho a_3\\
r_2 = r_3\times r_1
\end{cases}
\end{equation*}
Finally, we can recover $t=\rho\mathcal{K}^{-1}b$. This method provides an implementation-ready way to decompose the camera matrix. In practice, the only unknown is the sign of the scale factor, $\epsilon$.